@startuml datenfluss
skinparam backgroundColor #ffffff
skinparam ArrowColor #333333
skinparam componentBackgroundColor #ffffcc
skinparam databaseBackgroundColor #lightblue
skinparam cloudBackgroundColor #ffccff
skinparam noteBackgroundColor #f0f0f0

title Text2SQL System - Datenflussdiagramm (6 Phasen)
note top: GPT-5.2 | ReAct+RAG | 45ms (cached) | 88% Accuracy

' =================== DATENSPEICHER ===================
storage "D1: Schema\n(*.txt, 7.5KB)" as D1_Schema
storage "D2: KB\n(*.jsonl, 10KB)" as D2_KB
storage "D3: Meanings\n(*.json, 15KB)" as D3_Meanings
storage "D4: Vectors\n(ChromaDB)" as D4_Vector
storage "D5: Caches\n(4-Level)" as D5_Cache
storage "D6: SQLite\nDatabases" as D6_SQLite

' =================== ACTORS & COMPONENTS ===================
actor "ðŸ‘¤ User" as User
component "Frontend\n(React)" as Frontend
component "P0: Input\nValidator" as P0_Input
component "P1a: Cache\nLoader" as P1_Cache
component "P1b: Vector\nRetriever" as P1_Vector
component "P1c: KB\nLoader" as P1_KB
component "P2: Ambiguity\nDetector" as P2_Ambig
component "P3: SQL\nGenerator\n(ReAct)" as P3_SQL
component "P4a: SQL Guard" as P4a_Guard
component "P4b: LLM\nValidator" as P4b_Valid
component "P5: Query\nExecutor" as P5_Exec
component "P6: Summarizer" as P6_Summary
component "P7: Response\nBuilder" as P7_Resp
cloud "â˜ï¸ OpenAI API\n(GPT-5.2)" as E1_OpenAI

' =================== MAIN FLOW ===================

User --> Frontend: 1. Input
Frontend --> P0_Input: 2. POST /query

P0_Input --> P1_Cache: 3a. Cache
P0_Input --> P1_KB: 3b. KB (parallel)

P1_Cache -.-> D5_Cache: Check (95% Hit)
alt Cache Hit
  P1_Cache --> P1_Vector: [10ms]
else Cache Miss
  P1_Cache --> D1_Schema: Load [500ms]
  D1_Schema --> P1_Vector: schema
  P1_Vector --> D4_Vector: Index
  D4_Vector --> P1_Vector: chunks
  P1_Vector --> D5_Cache: Cache
end

P1_KB --> D2_KB: Load KB
D2_KB --> P1_KB: kb_text
P1_KB --> D3_Meanings: Load
D3_Meanings --> P1_KB: meanings

P1_Vector --> P2_Ambig: context
P1_KB --> P2_Ambig: kb, meanings
P2_Ambig --> E1_OpenAI: Ambiguity [500ms]
E1_OpenAI --> P2_Ambig: score

P1_Vector --> P3_SQL: context [2KB]
P1_KB --> P3_SQL: kb (Few-Shot!)
P3_SQL --> E1_OpenAI: ReAct [2-4s]\n(Iterate: Thinkâ†’Actâ†’Observe)
E1_OpenAI --> P3_SQL: {sql, confidence}

P2_Ambig --> P4a_Guard: result
P4a_Guard -.-> D1_Schema: Check
P4a_Guard --> P4b_Valid: SQL (if safe)

P4b_Valid --> E1_OpenAI: Validate [1-2s]\n"Semantics OK?"
E1_OpenAI --> P4b_Valid: result

P4b_Valid --> P5_Exec: validated_sql

P5_Exec -.-> D6_SQLite: Execute\n[0.5-10s]
D6_SQLite --> P5_Exec: results

P5_Exec -.-> D5_Cache: Cache\n(TTL: 5min)

P5_Exec --> P6_Summary: results
P6_Summary --> E1_OpenAI: Summary [1-2s]
E1_OpenAI --> P6_Summary: text

P6_Summary --> P7_Resp: summary
P7_Resp --> Frontend: QueryResponse

Frontend --> User: âœ… Display\n[SQL] [Table] [Summary]

note bottom
  **ðŸ“Š Performance:**
  â€¢ With Cache: 45ms
  â€¢ Without: 6.2s
  â€¢ Hit Rate: 95%
  
  **ðŸ’° Cost:**
  â€¢ Old: $0.45/query
  â€¢ New: $0.12-0.18
  â€¢ Savings: 73%
  
  **âœ“ Quality:**
  â€¢ Accuracy: 88%
  â€¢ Safety: 99.8%
  â€¢ Tokens: 1400 avg
end note


' =================== INPUT: BENUTZER ===================
actor "ðŸ‘¤ User" as User

' =================== FRONTEND ===================
component "Frontend\n(React)" as Frontend

' =================== PROZESSE (HAUPTFLOW VON LINKS NACH RECHTS) ===================

' P1: INPUT HANDLER
component "P1: Input\nHandler" as P1_Input

' P2: SCHEMA LOADING
component "P2: Schema\nLoader" as P2_Schema

' P3: KB LOADING
component "P3: KB/Meanings\nLoader" as P3_KB

' P4+P5: PARALLEL LLM PROCESSING
component "P4: Ambiguity\nDetector" as P4_Ambig
component "P5: SQL\nGenerator" as P5_SQL

' P6: VALIDATION
component "P6: Validator\n(3-fach)" as P6_Valid

' P7: EXECUTION
component "P7: Query\nExecutor" as P7_Exec

' P8: RESPONSE
component "P8: Response\nBuilder" as P8_Resp

' =================== EXTERNE SYSTEME ===================
cloud "â˜ï¸ OpenAI API\n(GPT-4)" as E1_OpenAI

' =================== HAUPTFLUSS: INPUT PHASE ===================
User --> Frontend: 1. Frage eingeben\n(question, db, page)
Frontend --> P1_Input: 2. POST /query\n{question, database, page, page_size}

' =================== PHASE 2: CONTEXT LOADING (PARALLEL) ===================

P1_Input --> P2_Schema: 3a. Load Schema
P1_Input --> P3_KB: 3b. Load KB

P2_Schema -.up-> D5_Cache: Cache Check
D5_Cache -.down-> P2_Schema: Hit/Miss
P2_Schema -.down-> D1_Schema: Load (cache miss)
D1_Schema -.down-> P2_Schema: schema_text
P2_Schema -.up-> D4_Vector: Index embeddings
D4_Vector -.down-> P2_Schema: chunks

P3_KB -.up-> D2_KB: Load KB
D2_KB -.down-> P3_KB: kb_text
P3_KB -.up-> D3_Meanings: Load Meanings
D3_Meanings -.down-> P3_KB: meanings_text

' =================== PHASE 3: PARALLEL LLM PROCESSING ===================

P2_Schema --> P4_Ambig: schema_context
P3_KB --> P4_Ambig: kb_text, meanings

P2_Schema --> P5_SQL: schema_context
P3_KB --> P5_SQL: kb_text, meanings

P4_Ambig --> E1_OpenAI: 4a. Ambiguity\nPrompt
E1_OpenAI --> P4_Ambig: ambiguity_score

P5_SQL --> E1_OpenAI: 4b. SQL Gen\nPrompt (ReAct)
E1_OpenAI --> P5_SQL: generated_sql

' =================== PHASE 4: VALIDIERUNG ===================

P4_Ambig --> P6_Valid: ambiguity_result
P5_SQL --> P6_Valid: sql_candidate

P6_Valid -.up-> D1_Schema: 5a. Schema Check
D1_Schema -.down-> P6_Valid: valid/invalid

P6_Valid --> E1_OpenAI: 5b. Semantic Check
E1_OpenAI --> P6_Valid: validation_score

P6_Valid -.up-> D4_Vector: 5c. Context Check
D4_Vector -.down-> P6_Valid: context_ok

' =================== PHASE 5: EXECUTION ===================

P6_Valid --> P7_Exec: safe_sql\n+ db_name

P7_Exec -.down-> D6_SQLite: Execute SQL
D6_SQLite -.down-> P7_Exec: raw_rows\nrow_count

P7_Exec -.up-> D5_Cache: Cache results
D5_Cache -.down-> P7_Exec: cached

P7_Exec --> P7_Exec: Apply Paging

' =================== PHASE 6: RESPONSE ===================

P7_Exec --> P8_Resp: results_page\nrow_count

P8_Resp --> Frontend: QueryResponse\n{sql, results, row_count, explanation}

Frontend --> User: 6. Display Results\n(Web UI mit Paging)

' =================== NOTIZEN ===================

note right of D1_Schema
  **Datenspeicher (OBEN):**
  Alle Datenspeicher sind oben
  angeordnet und werden von
  Prozessen abgerufen
end note

note right of D6_SQLite
  **Datenspeicher (UNTEN):**
  SQLite-Datenbanken mit
  Abfrage und Caching
end note

note right of P4_Ambig
  **Parallele Verarbeitung:**
  P4 & P5 laufen parallel
  â†’ OpenAI wird effizient genutzt
  â†’ Zeitersparnis
end note

note right of P6_Valid
  **3-fache Validierung:**
  âœ“ Schema-Compliance (D1)
  âœ“ Semantic-Check (E1)
  âœ“ Context-Integrity (D4)
end note

legend right
  |<#ffcccc> INPUT |
  |<#ffffcc> PROZESSE |
  |<#ffe6ff> FRONTEND |
  |<#ffccff> EXTERN |
  |<#lightblue> DATENSPEICHER |
end legend

@enduml

@startuml datenfluss
skinparam backgroundColor #ffffff
skinparam ArrowColor #333333
skinparam componentBackgroundColor #ffffcc
skinparam databaseBackgroundColor #lightblue
skinparam cloudBackgroundColor #ffccff
skinparam noteBackgroundColor #f0f0f0

title Text2SQL System - Datenflussdiagramm (6 Phasen, Detailliert)
note as N1
  GPT-5.2 | ReAct+RAG | 45ms (cached) | 88% Accuracy | 4-Level Caching
end note

' =================== DATENSPEICHER ===================
storage "D1: Schema\n(*.txt, 7.5KB)" as D1_Schema
storage "D2: KB\n(*.jsonl, 10KB)" as D2_KB
storage "D3: Meanings\n(*.json, 15KB)" as D3_Meanings
storage "D4: Vectors\n(ChromaDB)" as D4_Vector
storage "D5: Caches\n(4-Level, LRU+TTL)" as D5_Cache
storage "D6: SQLite\nDatabases" as D6_SQLite

' =================== ACTORS & COMPONENTS ===================
actor "ğŸ‘¤ User" as User
component "Frontend\n(React)" as Frontend
component "P0: Input\nValidator" as P0_Input
component "P1: Context\nLoader" as P1_Context
component "P2: Ambiguity\nDetector\n(ReAct)" as P2_Ambig
component "P3: SQL\nGenerator\n(ReAct+RAG)" as P3_SQL
component "P4a: SQL\nGuard\n(Regex)" as P4a_Guard
component "P4b: LLM\nValidator" as P4b_Valid
component "P5: Query\nExecutor\n(Paging)" as P5_Exec
component "P6: Result\nSummarizer\n(Optional)" as P6_Summary
component "P7: Response\nBuilder" as P7_Resp

cloud "â˜ï¸ OpenAI API\n(GPT-5.2)\nCompletions + Embeddings" as E1_OpenAI

' =================== FLOW START ===================

User --> Frontend: 1. Input: question,\ndatabase, page
Frontend --> P0_Input: 2. POST /query\n{question, database, page, page_size}

' =================== PHASE 1: CONTEXT LOADING ===================

note left of P1_Context
  **PHASE 1: Context Loading**
  (500ms | 10ms with cache)
end note

P0_Input --> P1_Context: 3. Load Context

P1_Context -.-> D5_Cache: Cache Check\n(95% Hit Rate)
D5_Cache -.-> P1_Context: Hit/Miss

' Cache Hit Path (95%)
P1_Context --> P1_Context: schema_text [10ms]\n(Cache Hit 95%)

' Cache Miss Path (5%)
P1_Context --> D1_Schema: Load schema.txt\n(Cache Miss 5%)
D1_Schema --> P1_Context: raw_schema [500ms]
P1_Context --> D4_Vector: Vectorize chunks\n(text-embedding-3-small)
D4_Vector --> E1_OpenAI: Embedding API
E1_OpenAI --> D4_Vector: vectors
D4_Vector --> P1_Context: indexed_chunks
P1_Context --> D5_Cache: Cache (TTL: 1h)

P1_Context --> D2_KB: Load KB (parallel)
D2_KB --> P1_Context: kb_text

P1_Context --> D3_Meanings: Load Meanings (parallel)
D3_Meanings --> P1_Context: meanings_text

' =================== PHASE 2 & 3: PARALLEL LLM PROCESSING ===================

note right of P2_Ambig
  **PHASE 2 & 3: LLM Processing**
  (PARALLEL, 4 seconds total)
  
  P2: Ambiguity Detection
  P3: SQL Generation (ReAct)
end note

P1_Context --> P2_Ambig: schema_text,\nkb_text, meanings
P2_Ambig --> E1_OpenAI: POST /completions\n(ambiguity_prompt)\n[500ms]
E1_OpenAI --> P2_Ambig: {is_ambiguous,\n ambiguity_score,\n clarifying_questions[]}

P1_Context --> P3_SQL: schema_text (2KB),\nkb_text (Few-Shot),\nmeanings

P3_SQL --> P3_SQL: **ReAct Loop**\nIteration 1: Analyze
P3_SQL --> E1_OpenAI: Thoughtâ†’Action\n[search for context]
E1_OpenAI --> P3_SQL: response
P3_SQL --> D4_Vector: Vector search\n(top_k=5 chunks)
D4_Vector --> P3_SQL: relevant_chunks

P3_SQL --> P3_SQL: Iteration 2: Generate SQL
P3_SQL --> E1_OpenAI: POST /completions\n(few_shot_prompt +\nretrieved_context)\n[2-4s]
E1_OpenAI --> P3_SQL: {generated_sql,\n explanation,\n confidence: 0.0-1.0}

' =================== PHASE 4: VALIDATION (3-LAYER) ===================

note left of P4a_Guard
  **PHASE 4: Validation (3-Layer)**
  L1: SQL Guard (10ms)
  L2: LLM Semantic (1-2s)
  L3: Schema Check (implicit)
end note

P2_Ambig --> P4a_Guard: result +\ngenerated_sql

P4a_Guard -.-> D1_Schema: Validate against\nschema

P4a_Guard --> P4a_Guard: Check Regex:\nâœ“ No DELETE/DROP/INSERT\nâœ“ Only SELECT/WITH\nâœ“ Known tables only\nâœ“ Single statement

' If Injection Detected
P4a_Guard --> P7_Resp: STOP: Error\n(Injection Detected)

' If Safe
P4a_Guard --> P4b_Valid: SQL passed\nsecurity check\n(Safe)

P4b_Valid --> E1_OpenAI: POST /completions\n(validation_prompt)\n"Is SQL semantically\ncorrect and safe?"\n[1-2s]
E1_OpenAI --> P4b_Valid: {is_valid: bool,\n validation_score,\n issues[], severity}

' If Validation FAIL (High Severity)
P4b_Valid --> P7_Resp: STOP: Error\n(Validation FAIL)

' If Validation OK
P4b_Valid --> P5_Exec: validated_sql\n(Validation OK)

' =================== PHASE 5: EXECUTION ===================

note right of P5_Exec
  **PHASE 5: Query Execution**
  (0.5-10 seconds)
  Includes paging & caching
end note

P5_Exec --> D6_SQLite: Execute SQL\nSELECT ... FROM ...\nLIMIT 100 OFFSET 0

D6_SQLite --> P5_Exec: {rows: [{...}, {...}],\n row_count: int,\n total_pages: int}

P5_Exec --> D5_Cache: Cache Results\n(TTL: 5min, L3)
D5_Cache --> P5_Exec: âœ“

P5_Exec --> D5_Cache: Cache Session\n(TTL: 1h, L4)\nFor paging consistency
D5_Cache --> P5_Exec: âœ“

' =================== PHASE 6: SUMMARIZATION ===================

note left of P6_Summary
  **PHASE 6: Summarization**
  (1-2 seconds, Optional)
end note

P5_Exec --> P6_Summary: results[],\nquestion

P6_Summary --> E1_OpenAI: POST /completions\n(summarization_prompt)\n"Write 2-3 sentences\nabout results"\n[1-2s]
E1_OpenAI --> P6_Summary: summary_text

' =================== RESPONSE BUILDING & DISPLAY ===================

note right of P7_Resp
  **Response Building & Display**
end note

P6_Summary --> P7_Resp: summary +\nresults +\nmetrics

P7_Resp --> Frontend: QueryResponse {\n  question,\n  generated_sql,\n  results,\n  row_count,\n  total_pages,\n  summary,\n  validation_score,\n  metrics: {latency_ms, tokens}}

Frontend --> User: âœ… **Results Display**\n[SQL Code Block]\n[Results Table, Page N/M]\n[Summary Text]\n[Confidence Score]

' =================== METRICS & LEGEND ===================

note bottom
  **ğŸ“Š PERFORMANCE METRICS**
  
  **Latency (6 Phases):**
  â””â”€ Cache Hit (95%): 45ms
  â””â”€ Cache Miss (5%): 6.2s
     â”œâ”€ Phase 1: 500ms | 10ms
     â”œâ”€ Phase 2: 500ms (parallel)
     â”œâ”€ Phase 3: 2-4s (parallel)
     â”œâ”€ Phase 4: 2s
     â”œâ”€ Phase 5: 0.5-10s
     â””â”€ Phase 6: 1-2s
  
  **ğŸ’° COST OPTIMIZATION:**
  â”œâ”€ Old (GPT-4o-mini): $0.45/query
  â”œâ”€ New (GPT-5.2): $0.12-0.18/query
  â””â”€ **SAVINGS: 73%** âœ…
  
  **âœ“ QUALITY METRICS:**
  â”œâ”€ Accuracy: 88%
  â”œâ”€ Safety: 99.8%
  â”œâ”€ Avg Tokens: 1400 (was 5500)
  â””â”€ Confidence: 0.87 avg
  
  **ğŸ”„ CACHING (4-Level):**
  â”œâ”€ L1 Schema (LRU): 95% Hit Rate
  â”œâ”€ L2 KB (TTL: 1h): 80% Hit Rate
  â”œâ”€ L3 Query Results (TTL: 5min): 70% Hit Rate
  â””â”€ L4 Sessions (TTL: 1h): 85% Hit Rate
     = **42x FASTER** for cached queries!
  
  **ğŸ›¡ï¸ VALIDATION GATES:**
  âœ“ Cache availability check
  âœ“ Schema completeness
  âœ“ SQL injection detection
  âœ“ Table/column compliance
  âœ“ Semantic correctness
  âœ“ Query execution success
  âœ“ Paging consistency
end note

@enduml

@startuml datenfluss
skinparam backgroundColor #ffffff
skinparam ArrowColor #333333
skinparam componentBackgroundColor #ffffcc
skinparam databaseBackgroundColor #lightblue
skinparam cloudBackgroundColor #ffccff
skinparam noteBackgroundColor #f0f0f0

title Text2SQL System - Datenflussdiagramm (6 Phasen, ReAct+RAG)
note top: Version 2.1 | GPT-5.2 | 45ms (cached) | 88% Accuracy | 4-Level Caching

' =================== DATENSPEICHER ===================
storage "D1: Schema Files\n(*.txt) 7.5 KB/DB" as D1_Schema
storage "D2: KB Files\n(*.jsonl) 10 KB" as D2_KB
storage "D3: Meanings\n(*.json) 15 KB" as D3_Meanings
storage "D4: Vector Store\n(ChromaDB)" as D4_Vector
storage "D5: Caches (4-Level)\nL1:Schema, L2:KB, L3:Query, L4:Session" as D5_Caches
storage "D6: SQLite\nDatabases" as D6_SQLite

' =================== INPUT & FRONTEND ===================
actor "ðŸ‘¤ User" as User
component "Frontend\n(React)" as Frontend
component "P0: Input\nValidator" as P0_Input

' =================== PHASE 1: CONTEXT LOADING ===================
component "P1a: Cache\nLoader" as P1_Cache
component "P1b: Vector\nRetriever" as P1_Vector
component "P1c: KB\nLoader" as P1_KB

' =================== PHASE 2 & 3: LLM PROCESSING (PARALLEL) ===================
component "P2: Ambiguity\nDetector" as P2_Ambig
component "P3: SQL\nGenerator\n(ReAct Loop)" as P3_SQL

' =================== PHASE 4: VALIDATION (3-LAYER) ===================
component "P4a: SQL Guard\n(Regex, 10ms)" as P4a_Guard
component "P4b: LLM Semantic\nValidator" as P4b_Valid

' =================== PHASE 5: EXECUTION ===================
component "P5: Query\nExecutor\n(Paging)" as P5_Exec

' =================== PHASE 6: SUMMARIZATION ===================
component "P6: Result\nSummarizer\n(Optional)" as P6_Summary

' =================== RESPONSE ===================
component "P7: Response\nBuilder" as P7_Resp

' =================== EXTERNAL SERVICES ===================
cloud "â˜ï¸ OpenAI API\n(GPT-5.2, Embeddings)\n$0.12-0.18/query" as E1_OpenAI

' =================== MAIN FLOW: USER â†’ FRONTEND â†’ BACKEND ===================

User --> Frontend: 1. Frage eingeben\n(question, database, page)
Frontend --> P0_Input: 2. POST /query\n{question, database, page, page_size}

' =================== PHASE 1: CONTEXT LOADING ===================

note top of P1_Cache
  **PHASE 1: Context Loading (500ms | 10ms cached)**
end note

P0_Input --> P1_Cache: 3a. Get Schema\n(db_name)
P0_Input --> P1_KB: 3b. Get KB\nParallel

P1_Cache -.-> D5_Caches: Cache Check\n(95% Hit Rate)
D5_Caches -.-> P1_Cache: Hit/Miss

alt Cache Hit
  P1_Cache --> P1_Vector: Skip file load\n(10ms)
else Cache Miss (5%)
  P1_Cache --> D1_Schema: Load schema.txt\n(500ms)
  D1_Schema --> P1_Vector: schema_text
  P1_Vector --> D4_Vector: Index in ChromaDB
  D4_Vector --> P1_Vector: vector_chunks
  P1_Vector --> D5_Caches: Cache for 1h\n(TTL)
  D5_Caches --> P1_Vector: âœ“
end

P1_KB --> D2_KB: Load KB
D2_KB --> P1_KB: kb_text
P1_KB --> D3_Meanings: Load Meanings
D3_Meanings --> P1_KB: meanings_text

' =================== PHASE 2 & 3: PARALLEL LLM PROCESSING ===================

note top of P2_Ambig
  **PHASE 2 & 3: LLM Processing (PARALLEL, 4s)**
  - Phase 2: Ambiguity Detection
  - Phase 3: SQL Generation (ReAct)
end note

P1_Vector --> P2_Ambig: schema_context\n(relevant chunks only)
P1_KB --> P2_Ambig: kb_text, meanings_text

P2_Ambig --> E1_OpenAI: 4a. POST /completions\n(ambiguity_prompt)
E1_OpenAI --> P2_Ambig: {is_ambiguous,\n ambiguity_score,\n questions[]}

P1_Vector --> P3_SQL: schema_context\n(2KB relevant)
P1_KB --> P3_SQL: kb_text\n(Few-Shot Examples!)

P3_SQL --> E1_OpenAI: 4b. ReAct Loop\n(iterate: Thinkâ†’Actionâ†’Observe)\nPOST /completions
E1_OpenAI --> P3_SQL: {sql, explanation,\n confidence: 0.0-1.0}

note right of P3_SQL
  **ReAct Details:**
  â€¢ Iteration 1: Analyze question
  â€¢ Search vector store for relevant chunks
  â€¢ Iteration 2: Generate SQL with context
  â€¢ Few-Shot examples guide generation
  â€¢ Max 2 iterations to prevent loops
end note

' =================== PHASE 4: VALIDATION (3-LAYER) ===================

note top of P4a_Guard
  **PHASE 4: Validation (3-Layer, 2s)**
  L1: SQL Guard (Regex, 10ms)
  L2: LLM Semantic (1-2s)
  L3: Query Check (implicit)
end note

P2_Ambig --> P4a_Guard: ambiguity_result +\ngenerated_sql

P4a_Guard -.-> D1_Schema: Check against schema

P4a_Guard --> P4b_Valid: SQL passed security\nOR STOP if injection detected

P4b_Valid --> E1_OpenAI: 5. POST /completions\n(validation_prompt)\n"Is SQL semantically correct?"
E1_OpenAI --> P4b_Valid: {is_valid,\n validation_score,\n issues[],\n severity}

' =================== PHASE 5: EXECUTION ===================

note top of P5_Exec
  **PHASE 5: Query Execution (0.5-10s)**
end note

P4b_Valid --> P5_Exec: validated_sql\nOR FAIL if high severity

P5_Exec -.-> D6_SQLite: Execute\nSELECT ... LIMIT 100 OFFSET 0
D6_SQLite -.-> P5_Exec: {rows[],\n row_count,\n total_pages}

P5_Exec -.-> D5_Caches: Cache results\n(TTL: 5min, L3)\nCache session\n(TTL: 1h, L4 for paging)

' =================== PHASE 6: SUMMARIZATION ===================

note top of P6_Summary
  **PHASE 6: Result Summarization (1-2s, Optional)**
end note

P5_Exec --> P6_Summary: results[]\n+ question

P6_Summary --> E1_OpenAI: 6. POST /completions\n(summarization_prompt)\n"Write 2-3 sentences about these results"
E1_OpenAI --> P6_Summary: summary_text

' =================== RESPONSE BUILDING ===================

P6_Summary --> P7_Resp: summary

P7_Resp -.-> D5_Caches: Cache everything\nfor consistency

P7_Resp --> Frontend: QueryResponse {\n  sql, results, row_count,\n  total_pages, summary,\n  validation_score, metrics}

Frontend --> User: âœ… Results Display\n[SQL] [Table, page N/M]\n[Summary] [Confidence]

' =================== METRICS BOX ===================

note bottom
  **ðŸ“Š Performance Metrics:**
  
  **Latency Breakdown:**
  â””â”€ Cache Hit (95%): 45ms
  â””â”€ Cache Miss (5%): 6.2s
     â”œâ”€ P1 (Context): 500ms + 10ms
     â”œâ”€ P2-3 (LLM): 4s (parallel)
     â”œâ”€ P4 (Validation): 2s
     â”œâ”€ P5 (Execution): 1-10s
     â””â”€ P6 (Summary): 1-2s
  
  **Cost Reduction:**
  â””â”€ Old (GPT-4o-mini): $0.45/query
  â””â”€ New (GPT-5.2): $0.12-0.18/query
  â””â”€ **Savings: 73%** âœ…
  
  **Quality Metrics:**
  â”œâ”€ Accuracy: 88%
  â”œâ”€ Safety: 99.8%
  â”œâ”€ Cache Hit Rate: 95%
  â””â”€ Avg Tokens: 1400 (was 5500)
  
  **Caching Strategy:**
  â”œâ”€ L1: Schema (LRU, no TTL, 95% HR)
  â”œâ”€ L2: KB (TTL: 1h, 80% HR)
  â”œâ”€ L3: Query Results (TTL: 5min, 70% HR)
  â””â”€ L4: Sessions (TTL: 1h, 85% HR â†’ 42x faster!)
  
  **Validation Gates:**
  âœ“ Cache availability
  âœ“ Schema completeness
  âœ“ SQL injection detection
  âœ“ Schema compliance
  âœ“ Semantic correctness
  âœ“ Query execution success
  âœ“ Paging consistency
end note

@enduml

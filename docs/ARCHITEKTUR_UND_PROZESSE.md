# Architektur & Prozesse - Text2SQL System

## ğŸ“– Inhaltsverzeichnis
1. [System-Ãœbersicht](#system-Ã¼bersicht)
2. [Detaillierter Prozessablauf](#detaillierter-prozessablauf)
3. [Komponenten & ihre Rollen](#komponenten--ihre-rollen)
4. [Datenfluss & Pipeline](#datenfluss--pipeline)
5. [Frontend-Backend Kommunikation](#frontend-backend-kommunikation)
6. [Technologische Entscheidungen](#technologische-entscheidungen)

---

## System-Ãœbersicht

### Was ist das System?

**Text2SQL** ist ein System, das **natÃ¼rliche Sprache in SQL-Abfragen Ã¼bersetzt**. Ein Nutzer stellt eine Frage in normaler Sprache (z.B. "Zeige mir alle Premium-Kunden mit hoher FinanzstabilitÃ¤t"), und das System generiert automatisch die entsprechende SQL-Query, fÃ¼hrt sie aus und prÃ¤sentiert die Ergebnisse.

### Architektur auf hÃ¶chster Ebene

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    FRONTEND (React)                         â”‚
â”‚  â€¢ Nutzer-Interface                                         â”‚
â”‚  â€¢ Frage-Input, Paging-Steuerung                            â”‚
â”‚  â€¢ Ergebnisanzeige mit SQL-Visualization                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚ HTTP/REST (JSON)
                         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 FASTAPI BACKEND                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  API Endpoint: POST /query                           â”‚   â”‚
â”‚  â”‚  â€¢ Entgegennahme der Nutzer-Anfrage                  â”‚   â”‚
â”‚  â”‚  â€¢ Koordination aller 6 Pipeline-Stufen              â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚                   â”‚                   â”‚
     â–¼                   â–¼                   â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚   LLM   â”‚      â”‚ Database â”‚      â”‚   Schema &   â”‚
  â”‚Generatorâ”‚      â”‚ Manager  â”‚      â”‚   KB Cache   â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Detaillierter Prozessablauf

### âš ï¸ WICHTIG: Kein Database Routing mehr!
Das System verwendet jetzt **immer** die Credit-Datenbank (`credit.sqlite`).
Database Routing wurde entfernt, da das Projekt nur die Credit-DB nutzt.
Dies vereinfacht die Architektur und macht sie stabiler (deterministisch).

### Phase 1: Anfrage-Entgegennahme & Context Loading

**Schritt 1.1: Frontend sendet Anfrage**
```
User: "Zeige mir Kunden mit hoher Schuldenlast nach Segment"
     â†“
Frontend POST /query
{
  "question": "Zeige mir Kunden mit hoher Schuldenlast nach Segment",
  "database": "credit",
  "page": 1,
  "page_size": 100
}
```

**Schritt 1.2: Backend lÃ¤dt Kontext (mit Caching)**

Der Backend lÃ¤dt vier Kontextdokumente parallel:

1. **Schema** (7,5 KB)
   - CREATE TABLE Statements fÃ¼r alle Tabellen
   - Beispielzeilen von jeder Tabelle (wichtig fÃ¼r JSON-Spalten!)
   - Foreign Key Beziehungen
   - **Caching**: LRU-Cache (unendlich, Ã¤ndert sich nie)

2. **Knowledge Base** (10 KB) - DomÃ¤nen-Wissen
   - 51 EintrÃ¤ge mit Definitionen von Metriken
   - Formeln: DTI = debincratio, CUR = credutil, FSI = 0.3Ã—(1-debincratio) + ...
   - Klassifizierungen: "Prime Customer", "Financially Vulnerable", etc.
   - **Caching**: TTL-Cache (1 Stunde, da Metriken stabil sind)
   - **WICHTIG**: KB wird nicht mehr in SQL-Prompts verwendet (nur fÃ¼r Ambiguity Detection)

3. **Column Meanings** (15 KB) - Spalten-Definitionen
   - Beschreibung jeder Spalte
   - JSON-Felder und ihre Unterkategorien
   - Datentypen und Beispielwerte
   - **Caching**: TTL-Cache (1 Stunde)

4. **BSL (Business Semantics Layer)** (~10 KB) - **NEU!**
   - Explizite Business Rules (generiert aus KB + Meanings)
   - Identity System: CU (clientref) vs CS (coreregistry)
   - Aggregation Patterns: Wann GROUP BY, wann ORDER BY + LIMIT
   - Business Rules: Financially Vulnerable, High-Risk, etc.
   - JSON Field Rules: Korrekte Tabellen-Qualifizierung
   - Join Chain Rules: Strikte Foreign-Key-Chain
   - **Caching**: TTL-Cache (1 Stunde)
   - **Format**: Plain-Text (`credit_bsl.txt`)

**Warum dieser Ansatz?**
- Nutzer wartet schneller (Caching)
- LLM erhÃ¤lt vollstÃ¤ndigen Kontext fÃ¼r bessere QualitÃ¤t
- **BSL-first**: Business Rules sind explizit dokumentiert (nicht implizit in Embeddings)
- **Deterministisch**: Gleiche Frage + BSL = gleiche SQL (reproduzierbar)
- Schema-Ã„nderungen sind selten (daher aggressives Caching)

---

### Phase 2: Ambiguity Detection (Mehrdeutigkeitserkennung)

**Schritt 2.1: LLM prÃ¼ft auf Mehrdeutigkeit**

```
LLM erhÃ¤lt:
- Nutzer-Frage
- Schema
- KB
- Column Meanings

LLM antwortet:
{
  "is_ambiguous": true,
  "reason": "Mehrere Interpretationen mÃ¶glich...",
  "questions": [
    "Welche Metriken fÃ¼r 'Schuldenlast'? (DTI, totliabs, LTV?)",
    "Nur Premium-Segmente oder alle?",
    "Mindestanzahl Kunden pro Segment?"
  ]
}
```

**Wann ist eine Frage mehrdeutig?**

âœ… MEHRDEUTIG (Pipeline stoppt):
- "debt burden" nicht eindeutig (DTI? totliabs? LTV?)
- "few customers" ohne Schwellenwert
- "relevant metrics" ohne Spezifizierung

âŒ NICHT mehrdeutig:
- Wording etwas vage, aber Absicht ist klar
- Schema/KB erlaubt ein Standardinterpretation
- ZuverlÃ¤ssige Default-Werte vorhanden

**Warum separat prÃ¼fen?**
- Verhindert falsche SQL-Generierung bevor sie passiert
- Feedback an Nutzer statt stilles Scheitern
- Spart OpenAI-Kosten (keine verschwendeten SQL-Generierungen)

---

### Phase 3: SQL-Generierung (BSL-first)

**Warum BSL-first statt ReAct + Retrieval?**

Alte Architektur (ReAct + RAG) âŒ:
```
- ReAct-Loop: THINK â†’ ACT â†’ OBSERVE â†’ REASON (mehrere Iterationen)
- Vector Store (ChromaDB): Semantische Suche nach relevanten Chunks
- Nicht-deterministisch: Gleiche Frage kann unterschiedliche SQL generieren
- Komplex: Vector Store, Embeddings, Retrieval-Logik
```

BSL-first Architektur âœ…:
```
- Direkte SQL-Generierung: Keine ReAct-Schleife
- VollstÃ¤ndiges Schema + Meanings + BSL im Prompt
- Deterministisch: Gleiche Frage + BSL = gleiche SQL
- Einfach: Plain-Text BSL statt Vector Store
```

**Detaillierter Ablauf:**

```
Schritt 3.1: Prompt-Aufbau (BSL-first)

Prompt-Struktur (in dieser Reihenfolge):
  1. BSL Overrides (hÃ¶chste PrioritÃ¤t)
  2. Business Semantics Layer (kritische Regeln)
  3. VollstÃ¤ndiges Schema + Beispieldaten
  4. Spalten-Bedeutungen (Meanings)
  5. Nutzer-Frage

BSL-Inhalt:
  - Identity System Rules: clientref (CU) vs coreregistry (CS)
  - Aggregation Patterns: Wann GROUP BY, wann ORDER BY + LIMIT
  - Business Rules: Financially Vulnerable, High-Risk, etc.
  - JSON Field Rules: Korrekte Tabellen-Qualifizierung
  - Join Chain Rules: Strikte Foreign-Key-Chain

Schritt 3.2: SQL-Generierung

LLM erhÃ¤lt vollstÃ¤ndigen Kontext:
  - Schema (7.5 KB): Alle Tabellen, Foreign Keys, Beispieldaten
  - Meanings (15 KB): Spalten-Definitionen, JSON-Felder
  - BSL (~10 KB): Explizite Business Rules
  - Nutzer-Frage

LLM muss BSL-Regeln befolgen:
  - Identity System: clientref (CU) fÃ¼r Output, coreregistry (CS) fÃ¼r JOINs
  - Aggregation: "by segment" â†’ GROUP BY, "top N" â†’ ORDER BY + LIMIT
  - Business Rules: "Financially Vulnerable" â†’ debincratio > 0.5 AND ...
  - Join Chain: Strikte Foreign-Key-Chain (nie Tabellen Ã¼berspringen)

SQL Generation:
  LLM generiert SQL direkt (keine ReAct-Schleife)
  LLM gibt zurÃ¼ck: {sql, explanation, confidence, bsl_rules_applied}

Result:
  {
    "sql": "SELECT cr.clientref, clientseg, AVG(debincratio) FROM ... GROUP BY ...",
    "explanation": "Diese Query aggregiert Schuldenlast pro Kundengruppe",
    "confidence": 0.87,
    "bsl_rules_applied": [
      "Identity: clientref for customer_id",
      "Aggregation: GROUP BY clientseg",
      "Business Rule: Financially Vulnerable"
    ]
  }
```

**Vorteile BSL-first:**
- âœ… Deterministisch: Gleiche Frage = gleiche SQL (reproduzierbar)
- âœ… Nachvollziehbar: BSL-Regeln sind explizit dokumentiert (Plain-Text)
- âœ… Einfach: Keine Vector Store-Dependencies, keine ReAct-Schleife
- âœ… Auditierbar: Business Rules kÃ¶nnen von Domain-Experten geprÃ¼ft werden
- âš ï¸ HÃ¶here Token-Kosten: ~32 KB statt ~2 KB, aber fÃ¼r Credit-DB akzeptabel

---

### Phase 4: SQL-Validierung (Hybrid Approach)

**Zwei Validierungs-Ebenen:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      Generated SQL Query                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
        â”‚ Rule-based  â”‚
        â”‚ Validation  â”‚
        â”‚ (SQL Guard) â”‚
        â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
               â”‚
     âœ“ Sicherheits-Checks?
       - Nur SELECT/WITH erlaubt
       - Keine INSERT/UPDATE/DELETE/DROP
       - Nur bekannte Tabellen
       - Max 1 Statement
               â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
        â”‚  LLM-based  â”‚
        â”‚ Validation  â”‚
        â”‚  (OpenAI)   â”‚
        â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
               â”‚
     âœ“ Semantische Korrektheit?
       - JOINs folgen FOREIGN KEY Chain?
       - Spalten korrekt qualifiziert?
       - JSON Pfade aus richtiger Tabelle?
       - GROUP BY/HAVING korrekt?
       - UNION ALL Spalten-KompatibilitÃ¤t?
               â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ âœ“ Valid â†’ Execute       â”‚
        â”‚ âœ— Errors â†’ Show to User â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Beispiel einer Validierung:**

```sql
SELECT clientseg, COUNT(*) cnt
FROM core_record
GROUP BY clientseg
HAVING COUNT(*) > 10
UNION ALL
SELECT 'Total', COUNT(*)
FROM core_record
ORDER BY clientseg DESC
```

LLM prÃ¼ft:
- âœ“ Syntax ist korrekt
- âœ“ Alle Tabellen existieren (core_record)
- âœ“ Spalten existieren (clientseg)
- âœ“ GROUP BY und HAVING konsistent
- âœ“ UNION ALL: beide SELECTs haben 2 Spalten (clientseg/text, cnt/number)
- âœ“ Kein INSERT/UPDATE/DELETE

Severity-Level:
- `low`: Style, funktioniert aber
- `medium`: KÃ¶nnte falsche Ergebnisse geben
- `high`: Query nicht ausfÃ¼hrbar

---

### Schritt 0.5: Session Management fÃ¼r Paging

**Purpose**: Speichern von Query-Kontext fÃ¼r schnelleres Paging und Follow-ups

**Verarbeitung nach erfolgreicher SQL-Generierung:**

```
1. query_id generieren:
   query_id = uuid4().hex  # z.B. "a1b2c3d4e5f6g7h8i9j0k1l2m3n4o5p6"

2. Session speichern in TTL Cache (TTL=1 Stunde):
   query_session_cache[query_id] = {
     "database": "credit",
     "sql": "SELECT clientseg, COUNT(*) FROM core_record GROUP BY clientseg",
     "question": "Zeige mir Kreditrisiken",
     "timestamp": 1705050000
   }

3. Response mit query_id zurÃ¼ckgeben:
   {
     "question": "Zeige mir Kreditrisiken",
     "generated_sql": "SELECT...",
     "results": [...],
     "row_count": 47,
     "query_id": "a1b2c3d4e5f6g7h8...",  // â† Wichtig!
     "page": 1,
     "total_pages": 1
   }
```

**Paging-Request (2. Request):**

```
Input: { 
  "query_id": "a1b2c3d4e5f6g7h8...",
  "page": 2
}

Processing:
1. query_id prÃ¼fen:
   session = query_session_cache.get(query_id)
   if not session:
     return Error("query_id abgelaufen oder ungÃ¼ltig")

2. Routing ÃœBERSPRINGEN!
   database = session["database"]  # â† Aus Session
   sql = session["sql"]            # â† Aus Session
   
3. Direkt zu Phase 5 (Execution):
   OFFSET = (page-1) * page_size
   LIMIT = page_size
   
   final_sql = f"{sql} LIMIT 100 OFFSET 100"  // Seite 2
   
4. AusfÃ¼hren und Results zurÃ¼ckgeben

â±ï¸  Timing: 2-3s statt 8-12s (70% schneller!)
```

**Sicherheit & Validierung:**

```python
# Ensure Database Consistency
if request.database and request.database != session.get("database"):
    return Error("query_id passt nicht zur angefragten Datenbank")

# Ensure Session TTL
if timestamp < now - 3600:
    return Error("query_id abgelaufen (> 1 Stunde)")
```

---

### Phase 5: SQL-AusfÃ¼hrung mit Paging

**Warum Paging?**
- Datenbank kann 10.000+ Zeilen zurÃ¼ckgeben
- Browser kann nicht 10.000 Zeilen auf einmal rendern
- Nutzer will nur erste 100 Zeilen sehen

**Paging-Prozess:**

```
Nutzer-Request: page=2, page_size=100
              â†“
Backend berechnet:
  - OFFSET = (page - 1) Ã— page_size = 100
  - LIMIT = 100
              â†“
Original SQL:
  SELECT ... FROM ... WHERE ...
              â†“
Paging-SQL:
  SELECT ... FROM ... WHERE ... LIMIT 100 OFFSET 100
              â†“
Auch berechnet:
  - Total Row Count (ohne LIMIT/OFFSET)
  - Total Pages = ceil(Total / page_size)
  - has_next_page, has_previous_page
              â†“
Response enthÃ¤lt:
  {
    results: [...],
    page: 2,
    total_pages: 47,
    total_rows: 4650,
    has_next_page: true,
    has_previous_page: true
  }
```

**Determinismus:**
- Paging muss immer gleiche Zeilen pro Seite zurÃ¼ckgeben
- DafÃ¼r wird ein Query-ID (UUID) erstellt
- Session speichert: database, SQL, question
- Zweiter Request mit gleicher Query-ID verwendet gespeicherte SQL

---

### Phase 6: Ergebniszusammenfassung

```
Input fÃ¼r LLM:
  - Nutzer-Frage: "Schuldenlast nach Segment"
  - Generierte SQL: "SELECT clientseg, AVG(debincratio), ..."
  - Erste 3 Ergebnis-Zeilen (als JSON)
  - Row-Count: 1247

LLM generiert:
  "Die Analyse zeigt, dass Premium-Kunden eine durchschnittliche 
   Schuldenquote von 32% haben, wÃ¤hrend Standard-Kunden bei 45% liegen. 
   Insgesamt wurden 1247 KundensÃ¤tze analysiert..."
```

**Warum?**
- Rohe Daten sind schwer zu verstehen
- NatÃ¼rlichsprachliche Zusammenfassung hilft Nutzer
- Gibt sofort wichtigste Insights

---

## Komponenten & ihre Rollen

### Frontend (React)

**Datei**: `frontend/src/App.jsx`

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Nutzer-Input             â”‚
â”‚   - Text eingeben          â”‚
â”‚   - Datenbank wÃ¤hlen       â”‚
â”‚   - Submit                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚  HTTP POST  â”‚
          â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â–¼             â–¼             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Ergebnisse
â”‚ darstellen
â”‚ Paging-
â”‚ Steuerung
â”‚ SQL
â”‚ anzeigen
â”‚ Kopieren
â”‚ Thema
â”‚ (Dark/Light)
```

**Key Features:**
- Dark/Light Theme
- Responsive Design
- SQL-Visualisierung mit Syntax-Highlighting
- Paging-Steuerung (Seite X von Y)
- Copy-to-Clipboard fÃ¼r SQL
- Error-Handling

### Backend Pipeline

**Datei**: `backend/main.py`

```
1. Schema Retrieval Module
   â””â”€ LÃ¤dt Schema (Core Record, Employment, Assets, ...)
   
2. LLM Generator Module
   â””â”€ Ambiguity Detection
   â””â”€ SQL Generation (mit ReAct)
   â””â”€ SQL Validation
   â””â”€ Result Summarization
   
3. Schema Retriever (RAG)
   â””â”€ ChromaDB Vector Store
   â””â”€ Semantische Suche
   
4. Database Manager
   â””â”€ Query Execution
   â””â”€ Paging Logic
   
5. Caching Layer
   â””â”€ Schema Cache (LRU)
   â””â”€ KB Cache (TTL: 1h)
   â””â”€ Query Result Cache (TTL: 5min)
   
6. Security Layer (SQL Guard)
   â””â”€ Regex-basierte SicherheitsprÃ¼fungen
```

### LLM-Generator (OpenAI)

**Modell**: Aktuell GPT-5.2

**Methoden:**
1. `check_ambiguity()` - MehrdeutigkeitsprÃ¼fung
2. `generate_sql()` - Standard SQL-Generierung
3. `generate_sql_with_react_retrieval()` - ReAct mit Retrieval
4. `validate_sql()` - LLM-basierte Validierung
5. `summarize_results()` - Ergebniszusammenfassung

---

## Datenfluss & Pipeline

### End-to-End Request Flow

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    USER SENDS QUESTION                    â•‘
â•‘        "Zeige Schuldenlast pro Kundengruppe"              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â”¬â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
              â”‚
              â–¼
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  PHASE 1: CONTEXT LOADING (Parallel, mit Caching)         â•‘
â•‘  â””â”€ Schema: CREATE TABLE + Beispielzeilen (7.5 KB)        â•‘
â•‘  â””â”€ KB: 51 Metriken & Formeln (10 KB)                     â•‘
â•‘  â””â”€ Meanings: Spalten-Definitionen (15 KB)                â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â”¬â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
              â”‚
              â–¼
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  PHASE 2: AMBIGUITY DETECTION (Parallel mit SQL Gen)      â•‘
â•‘  â””â”€ LLM prÃ¼ft: Ist Frage mehrdeutig?                      â•‘
â•‘  â””â”€ if mehrdeutig â†’ STOP & RÃ¼ckfragen an Nutzer           â•‘
â•‘  â””â”€ if klar â†’ Weiter zu Phase 3                           â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â”¬â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
              â”‚
              â–¼
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  PHASE 3: SQL GENERATION (BSL-first)                      â•‘
â•‘  â””â”€ Prompt-Aufbau: BSL + Schema + Meanings + Frage        â•‘
â•‘  â””â”€ Direkte SQL-Generierung (keine ReAct-Schleife)        â•‘
â•‘  â””â”€ LLM muss BSL-Regeln befolgen                          â•‘
â•‘  â””â”€ SQL wird generiert mit Confidence Score               â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â”¬â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
              â”‚
              â–¼
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  PHASE 4: SQL VALIDATION (Hybrid: Rule + LLM)             â•‘
â•‘  â””â”€ SQL Guard: SicherheitsprÃ¼fungen (Regex-basiert)       â•‘
â•‘  â””â”€ LLM Validator: Semantische Korrektheit                â•‘
â•‘  â””â”€ if Fehler â†’ Optional: Self-Correction Loop            â•‘
â•‘  â””â”€ if valide â†’ Weiter zu Phase 5                         â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â”¬â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
              â”‚
              â–¼
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  PHASE 5: EXECUTION + PAGING                              â•‘
â•‘  â””â”€ SQLite fÃ¼hrt Query aus                                â•‘
â•‘  â””â”€ Paging: OFFSET & LIMIT anwenden                       â•‘
â•‘  â””â”€ Berechne: Total Pages, has_next_page, etc.            â•‘
â•‘  â””â”€ Return: Results (100 Zeilen) + Metadaten              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â”¬â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
              â”‚
              â–¼
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  PHASE 6: RESULT SUMMARIZATION                             â•‘
â•‘  â””â”€ LLM erstellt natÃ¼rlichsprachliche Zusammenfassung      â•‘
â•‘  â””â”€ Zeigt wichtigste Insights                              â•‘
â•‘  â””â”€ Fallback: Wenn LLM-Call fehlschlÃ¤gt, alternative       â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â”¬â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
              â”‚
              â–¼
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘             JSON RESPONSE AN FRONTEND                      â•‘
â•‘  {                                                         â•‘
â•‘    question: "...",                                        â•‘
â•‘    generated_sql: "SELECT ...",                            â•‘
â•‘    results: [...],                                         â•‘
â•‘    page: 1, total_pages: 47,                               â•‘
â•‘    summary: "Die Analyse zeigt...",                        â•‘
â•‘    ambiguity_check, validation, query_id, ...              â•‘
â•‘  }                                                         â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
              â”‚
              â–¼
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘        FRONTEND RENDERS RESULTS TO USER                    â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

---

## Frontend-Backend Kommunikation

### Request Format

```javascript
POST /query HTTP/1.1
Content-Type: application/json

{
  "question": "Zeige Schuldenlast pro Segment",
  "database": "credit",
  "page": 1,
  "page_size": 100,
  "use_react": true,
  "query_id": null  // FÃ¼r Paging: UUID der Anfrage
}
```

### Response Format

```javascript
{
  // Basis-Info
  "question": "...",
  "generated_sql": "SELECT ...",
  
  // Ergebnisse + Paging
  "results": [
    { "clientseg": "Premium", "avg_dti": 0.32, ... },
    { "clientseg": "Standard", "avg_dti": 0.45, ... }
  ],
  "row_count": 3,
  "page": 1,
  "total_pages": 1,
  "total_rows": 3,
  "has_next_page": false,
  "has_previous_page": false,
  
  // Metadaten + Zusammenfassung
  "summary": "Die Analyse zeigt dass...",
  "explanation": "Diese Query aggregiert...",
  "notice": "Zeige Seite 1 von 1",
  
  // Validierung & Ambiguity
  "ambiguity_check": {
    "is_ambiguous": false,
    "reason": "..."
  },
  "validation": {
    "is_valid": true,
    "errors": [],
    "severity": "low"
  },
  
  // Session
  "query_id": "a1b2c3d4..."
}
```

---

## Technologische Entscheidungen

### 1. FastAPI vs. Flask vs. Django

**Entscheidung: FastAPI** âœ…

**GrÃ¼nde:**
- Automatic OpenAPI documentation
- Built-in JSON serialization
- Async support fÃ¼r parallelism
- Type hints & Pydantic validation
- Performance: ~17x schneller als Flask

**Alternative betrachtet:**
- Flask: Zu minimalistisch
- Django: Overkill fÃ¼r diese API

### 2. SQLite vs. PostgreSQL vs. MySQL

**Entscheidung: SQLite** âœ…

**GrÃ¼nde:**
- DatensÃ¤tze sind statisch (Mini-Interact Dataset)
- Keine Concurrent Writes nÃ¶tig
- Zero Configuration
- Perfekt fÃ¼r Uni-Projekt (keine Server-Setup)
- Schnell fÃ¼r Read-Operationen

### 3. OpenAI API vs. Open-Source LLMs

**Entscheidung: OpenAI (GPT-5.2)** âœ…

**GrÃ¼nde:**
- Beste QualitÃ¤t fÃ¼r SQL-Generierung
- ZuverlÃ¤ssige API
- Kosteneffizient (GPT-5.2)
- Schnelle Updates & neue Modelle

**Geplante Migration zu GPT-5.2:**
- Bessere Instruction Following
- HÃ¶here Accuracy bei komplexen Queries
- Bessere JSON-Parsing ZuverlÃ¤ssigkeit
- Kostenbenefit durch effizientere Token-Nutzung

### 4. ChromaDB vs. Pinecone vs. Weaviate

**Entscheidung: ChromaDB** âœ…

**GrÃ¼nde:**
- Open-source, kostenlos
- Keine externe Dependencies
- Lokal persistent (vector_store/)
- Einfach zu debuggen
- Perfekt fÃ¼r statisches Schema

### 5. Caching: LRU vs. Redis vs. Memcached

**Entscheidung: Hybrid (LRU + TTLCache)** âœ…

```python
# Schema: LRU Cache (unendlich, Ã¤ndert sich nie)
@lru_cache(maxsize=32)
def get_cached_schema(db_path):
    ...

# KB & Meanings: TTL Cache (1 Stunde)
kb_cache = TTLCache(maxsize=32, ttl=3600)

# Query Results: TTL Cache (5 Minuten)
query_cache = TTLCache(maxsize=100, ttl=300)
```

**GrÃ¼nde:**
- In-Process Caching (keine Netzwerk-Latenz)
- TTL fÃ¼r Konsistenz mit Daten
- LRU fÃ¼r Schema (sehr stabil)

---

## Zusammenfassung der Architektur

| Aspekt | Technologie | Grund |
|--------|-------------|-------|
| **Frontend** | React | Modern, Reactive, User-Friendly |
| **Backend API** | FastAPI | Async, Type-Safe, High-Performance |
| **Database** | SQLite | Static Data, No Setup, Fast Reads |
| **LLM** | OpenAI GPT-5.2 | Best Quality, API, Reliable |
| **Retrieval** | ChromaDB | Local, Free, Simple, Effective |
| **Caching** | LRU + TTL | Fast, Consistent, In-Process |
| **Validation** | Hybrid | Defense in Depth, Robust |

Diese Architektur ist:
- **Scalable**: Leicht auf andere Datenbanken ausweiterbar
- **Maintainable**: Klare Separation of Concerns
- **Robust**: Multiple Validierungs-Ebenen
- **Efficient**: Parallel Processing, Caching, ReAct-Retrieval
- **User-Friendly**: Dark Mode, Paging, Error Messages

# Architektur & Prozesse - Text2SQL System

## ğŸ“– Inhaltsverzeichnis
1. [System-Ãœbersicht](#system-Ã¼bersicht)
2. [Detaillierter Prozessablauf](#detaillierter-prozessablauf)
3. [Komponenten & ihre Rollen](#komponenten--ihre-rollen)
4. [Datenfluss & Pipeline](#datenfluss--pipeline)
5. [Frontend-Backend Kommunikation](#frontend-backend-kommunikation)
6. [Technologische Entscheidungen](#technologische-entscheidungen)

---

## System-Ãœbersicht

### Was ist das System?

**Text2SQL** ist ein System, das **natÃ¼rliche Sprache in SQL-Abfragen Ã¼bersetzt**. Ein Nutzer stellt eine Frage in normaler Sprache (z.B. "Zeige mir alle Premium-Kunden mit hoher FinanzstabilitÃ¤t"), und das System generiert automatisch die entsprechende SQL-Query, fÃ¼hrt sie aus und prÃ¤sentiert die Ergebnisse.

### Architektur auf hÃ¶chster Ebene

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    FRONTEND (React)                         â”‚
â”‚  â€¢ Nutzer-Interface                                         â”‚
â”‚  â€¢ Frage-Input, Paging-Steuerung                            â”‚
â”‚  â€¢ Ergebnisanzeige mit SQL-Visualization                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚ HTTP/REST (JSON)
                         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 FASTAPI BACKEND                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  API Endpoint: POST /query                           â”‚   â”‚
â”‚  â”‚  â€¢ Entgegennahme der Nutzer-Anfrage                  â”‚   â”‚
â”‚  â”‚  â€¢ Koordination aller 6 Pipeline-Stufen              â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚                   â”‚                   â”‚
     â–¼                   â–¼                   â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚   LLM   â”‚      â”‚ Database â”‚      â”‚   Schema &   â”‚
  â”‚Generatorâ”‚      â”‚ Manager  â”‚      â”‚   KB Cache   â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Detaillierter Prozessablauf

### Phase 1: Anfrage-Entgegennahme & Context Loading

**Schritt 1.1: Frontend sendet Anfrage**
```
User: "Zeige mir Kunden mit hoher Schuldenlast nach Segment"
     â†“
Frontend POST /query
{
  "question": "Zeige mir Kunden mit hoher Schuldenlast nach Segment",
  "database": "credit",
  "page": 1,
  "page_size": 100,
  "use_react": true
}
```

**Schritt 1.2: Backend lÃ¤dt Kontext (mit Caching)**

Der Backend lÃ¤dt drei Kontextdokumente parallel:

1. **Schema** (7,5 KB)
   - CREATE TABLE Statements fÃ¼r alle Tabellen
   - Beispielzeilen von jeder Tabelle (wichtig fÃ¼r JSON-Spalten!)
   - Foreign Key Beziehungen
   - **Caching**: LRU-Cache (unendlich, Ã¤ndert sich nie)

2. **Knowledge Base** (10 KB) - DomÃ¤nen-Wissen
   - 51 EintrÃ¤ge mit Definitionen von Metriken
   - Formeln: DTI = debincratio, CUR = credutil, FSI = 0.3Ã—(1-debincratio) + ...
   - Klassifizierungen: "Prime Customer", "Financially Vulnerable", etc.
   - **Caching**: TTL-Cache (1 Stunde, da Metriken stabil sind)

3. **Column Meanings** (15 KB) - Spalten-Definitionen
   - Beschreibung jeder Spalte
   - JSON-Felder und ihre Unterkategorien
   - Datentypen und Beispielwerte
   - **Caching**: TTL-Cache (1 Stunde)

**Warum dieser Ansatz?**
- Nutzer wartet schneller (Caching)
- LLM erhÃ¤lt vollstÃ¤ndigen Kontext fÃ¼r bessere QualitÃ¤t
- Schema-Ã„nderungen sind selten (daher aggressives Caching)

---

### Phase 2: Ambiguity Detection (Mehrdeutigkeitserkennung)

**Schritt 2.1: LLM prÃ¼ft auf Mehrdeutigkeit**

```
LLM erhÃ¤lt:
- Nutzer-Frage
- Schema
- KB
- Column Meanings

LLM antwortet:
{
  "is_ambiguous": true,
  "reason": "Mehrere Interpretationen mÃ¶glich...",
  "questions": [
    "Welche Metriken fÃ¼r 'Schuldenlast'? (DTI, totliabs, LTV?)",
    "Nur Premium-Segmente oder alle?",
    "Mindestanzahl Kunden pro Segment?"
  ]
}
```

**Wann ist eine Frage mehrdeutig?**

âœ… MEHRDEUTIG (Pipeline stoppt):
- "debt burden" nicht eindeutig (DTI? totliabs? LTV?)
- "few customers" ohne Schwellenwert
- "relevant metrics" ohne Spezifizierung

âŒ NICHT mehrdeutig:
- Wording etwas vage, aber Absicht ist klar
- Schema/KB erlaubt ein Standardinterpretation
- ZuverlÃ¤ssige Default-Werte vorhanden

**Warum separat prÃ¼fen?**
- Verhindert falsche SQL-Generierung bevor sie passiert
- Feedback an Nutzer statt stilles Scheitern
- Spart OpenAI-Kosten (keine verschwendeten SQL-Generierungen)

---

### Phase 3: SQL-Generierung mit ReAct + Retrieval

**Warum ReAct + Retrieval statt direkter Generierung?**

Direkter Ansatz âŒ:
```
Input: Ganze Schema (7.5 KB) + KB (10 KB) + Frage
       â†’ Token-Overkill (zu viel irrelevante Infos)
       â†’ Teurere API-Calls
       â†’ Mehr Fehler wegen Information Overload
```

ReAct + Retrieval âœ…:
```
Iteration 1:
  - LLM denkt: "Ich brauche: core_record.clientseg, employment_and_income.debincratio, ..."
  - Vector Retrieval sucht: "debt-to-income ratio", "customer segments"
  - Relevant Schema: 16 Chunks (statt ganzes Schema)
  - Relevant KB: 18 EintrÃ¤ge (statt alle 51)
  
Iteration 2:
  - LLM denkt: "Brauch ich noch fÃ¼r Aggregationen..."
  - Weitere Retrieval-Runde
  
Iteration 3:
  - Genug Info gesammelt
  - SQL wird generiert
```

**Detaillierter Ablauf:**

```
Schritt 3.1: LLM Thinking Phase
  "THINK: Die Frage fragt nach Schuldenlast pro Segment.
   Ich benÃ¶tige:
   - Kundensegmente (core_record.clientseg)
   - Schuldenlast-Metriken (debincratio, totliabs, ...)
   - MÃ¶gliche JOINs: core_record â†’ employment_and_income â†’ expenses_and_assets
   
   Search Queries:
   - 'debt-to-income ratio debincratio segment analysis'
   - 'customer segments clientseg premium standard'
   - 'total liabilities expenses assets'
   - 'foreign key relationships joins'"

Schritt 3.2: Vector Retrieval (ChromaDB + OpenAI Embeddings)
  FÃ¼r jeden Search Query:
  - Semantische Suche in Schema-Chunks
  - Semantische Suche in KB-EintrÃ¤gen
  - Semantische Suche in Column Meanings
  â†’ Top-5 Ergebnisse pro Query

Schritt 3.3: LLM Observation & Reasoning
  "OBSERVE: Ich habe:
   - Schema fÃ¼r: core_record, employment_and_income, expenses_and_assets
   - KB EintrÃ¤ge fÃ¼r DTI, Financial Vulnerability
   - Meanings fÃ¼r alle relevanten Spalten
   
   REASON: Habe ich genug Info?
   - âœ“ Kann debincratio extrahieren
   - âœ“ Kann GROUP BY clientseg machen
   - âœ“ Kann Aggregation durchfÃ¼hren
   â†’ Ja, genug Info. SQL generieren."

Schritt 3.4: SQL Generation
  Mit NUR relevanten Infos:
  
  WITH customer_debt AS (
    SELECT
      cr.clientseg,
      ei.debincratio,
      ea.totliabs,
      ...
    FROM core_record cr
    JOIN employment_and_income ei ON ei.emplcoreref = cr.coreregistry
    JOIN expenses_and_assets ea ON ea.expemplref = ei.emplcoreref
  ),
  segment_stats AS (
    SELECT
      clientseg,
      COUNT(*) AS customer_count,
      AVG(debincratio) AS avg_dti,
      ...
    FROM customer_debt
    GROUP BY clientseg
    HAVING COUNT(*) >= 10
  )
  SELECT * FROM segment_stats
  UNION ALL
  SELECT 'GRAND TOTAL', ...
  ORDER BY ...
```

**Vorteile ReAct + Retrieval:**
- 40-60% Token-Ersparnis (nur relevante Infos)
- 10-15% bessere Accuracy (weniger Noise)
- Schneller (weniger zu verarbeiten)

---

### Phase 4: SQL-Validierung (Hybrid Approach)

**Zwei Validierungs-Ebenen:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      Generated SQL Query                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
        â”‚ Rule-based  â”‚
        â”‚ Validation  â”‚
        â”‚ (SQL Guard) â”‚
        â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
               â”‚
     âœ“ Sicherheits-Checks?
       - Nur SELECT/WITH erlaubt
       - Keine INSERT/UPDATE/DELETE/DROP
       - Nur bekannte Tabellen
       - Max 1 Statement
               â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
        â”‚  LLM-based  â”‚
        â”‚ Validation  â”‚
        â”‚  (OpenAI)   â”‚
        â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
               â”‚
     âœ“ Semantische Korrektheit?
       - JOINs folgen FOREIGN KEY Chain?
       - Spalten korrekt qualifiziert?
       - JSON Pfade aus richtiger Tabelle?
       - GROUP BY/HAVING korrekt?
       - UNION ALL Spalten-KompatibilitÃ¤t?
               â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ âœ“ Valid â†’ Execute       â”‚
        â”‚ âœ— Errors â†’ Show to User â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Beispiel einer Validierung:**

```sql
SELECT clientseg, COUNT(*) cnt
FROM core_record
GROUP BY clientseg
HAVING COUNT(*) > 10
UNION ALL
SELECT 'Total', COUNT(*)
FROM core_record
ORDER BY clientseg DESC
```

LLM prÃ¼ft:
- âœ“ Syntax ist korrekt
- âœ“ Alle Tabellen existieren (core_record)
- âœ“ Spalten existieren (clientseg)
- âœ“ GROUP BY und HAVING konsistent
- âœ“ UNION ALL: beide SELECTs haben 2 Spalten (clientseg/text, cnt/number)
- âœ“ Kein INSERT/UPDATE/DELETE

Severity-Level:
- `low`: Style, funktioniert aber
- `medium`: KÃ¶nnte falsche Ergebnisse geben
- `high`: Query nicht ausfÃ¼hrbar

---

### Phase 5: SQL-AusfÃ¼hrung mit Paging

**Warum Paging?**
- Datenbank kann 10.000+ Zeilen zurÃ¼ckgeben
- Browser kann nicht 10.000 Zeilen auf einmal rendern
- Nutzer will nur erste 100 Zeilen sehen

**Paging-Prozess:**

```
Nutzer-Request: page=2, page_size=100
              â†“
Backend berechnet:
  - OFFSET = (page - 1) Ã— page_size = 100
  - LIMIT = 100
              â†“
Original SQL:
  SELECT ... FROM ... WHERE ...
              â†“
Paging-SQL:
  SELECT ... FROM ... WHERE ... LIMIT 100 OFFSET 100
              â†“
Auch berechnet:
  - Total Row Count (ohne LIMIT/OFFSET)
  - Total Pages = ceil(Total / page_size)
  - has_next_page, has_previous_page
              â†“
Response enthÃ¤lt:
  {
    results: [...],
    page: 2,
    total_pages: 47,
    total_rows: 4650,
    has_next_page: true,
    has_previous_page: true
  }
```

**Determinismus:**
- Paging muss immer gleiche Zeilen pro Seite zurÃ¼ckgeben
- DafÃ¼r wird ein Query-ID (UUID) erstellt
- Session speichert: database, SQL, question
- Zweiter Request mit gleicher Query-ID verwendet gespeicherte SQL

---

### Phase 6: Ergebniszusammenfassung

```
Input fÃ¼r LLM:
  - Nutzer-Frage: "Schuldenlast nach Segment"
  - Generierte SQL: "SELECT clientseg, AVG(debincratio), ..."
  - Erste 3 Ergebnis-Zeilen (als JSON)
  - Row-Count: 1247

LLM generiert:
  "Die Analyse zeigt, dass Premium-Kunden eine durchschnittliche 
   Schuldenquote von 32% haben, wÃ¤hrend Standard-Kunden bei 45% liegen. 
   Insgesamt wurden 1247 KundensÃ¤tze analysiert..."
```

**Warum?**
- Rohe Daten sind schwer zu verstehen
- NatÃ¼rlichsprachliche Zusammenfassung hilft Nutzer
- Gibt sofort wichtigste Insights

---

## Komponenten & ihre Rollen

### Frontend (React)

**Datei**: `frontend/src/App.jsx`

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Nutzer-Input             â”‚
â”‚   - Text eingeben          â”‚
â”‚   - Datenbank wÃ¤hlen       â”‚
â”‚   - Submit                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚  HTTP POST  â”‚
          â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â–¼             â–¼             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Ergebnisse
â”‚ darstellen
â”‚ Paging-
â”‚ Steuerung
â”‚ SQL
â”‚ anzeigen
â”‚ Kopieren
â”‚ Thema
â”‚ (Dark/Light)
```

**Key Features:**
- Dark/Light Theme
- Responsive Design
- SQL-Visualisierung mit Syntax-Highlighting
- Paging-Steuerung (Seite X von Y)
- Copy-to-Clipboard fÃ¼r SQL
- Error-Handling

### Backend Pipeline

**Datei**: `backend/main.py`

```
1. Schema Retrieval Module
   â””â”€ LÃ¤dt Schema (Core Record, Employment, Assets, ...)
   
2. LLM Generator Module
   â””â”€ Ambiguity Detection
   â””â”€ SQL Generation (mit ReAct)
   â””â”€ SQL Validation
   â””â”€ Result Summarization
   
3. Schema Retriever (RAG)
   â””â”€ ChromaDB Vector Store
   â””â”€ Semantische Suche
   
4. Database Manager
   â””â”€ Query Execution
   â””â”€ Paging Logic
   
5. Caching Layer
   â””â”€ Schema Cache (LRU)
   â””â”€ KB Cache (TTL: 1h)
   â””â”€ Query Result Cache (TTL: 5min)
   
6. Security Layer (SQL Guard)
   â””â”€ Regex-basierte SicherheitsprÃ¼fungen
```

### LLM-Generator (OpenAI)

**Modell**: Aktuell GPT-5.2

**Methoden:**
1. `check_ambiguity()` - MehrdeutigkeitsprÃ¼fung
2. `generate_sql()` - Standard SQL-Generierung
3. `generate_sql_with_react_retrieval()` - ReAct mit Retrieval
4. `validate_sql()` - LLM-basierte Validierung
5. `summarize_results()` - Ergebniszusammenfassung

---

## Datenfluss & Pipeline

### End-to-End Request Flow

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    USER SENDS QUESTION                    â•‘
â•‘        "Zeige Schuldenlast pro Kundengruppe"              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â”¬â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
              â”‚
              â–¼
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  PHASE 1: CONTEXT LOADING (Parallel, mit Caching)         â•‘
â•‘  â””â”€ Schema: CREATE TABLE + Beispielzeilen (7.5 KB)        â•‘
â•‘  â””â”€ KB: 51 Metriken & Formeln (10 KB)                     â•‘
â•‘  â””â”€ Meanings: Spalten-Definitionen (15 KB)                â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â”¬â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
              â”‚
              â–¼
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  PHASE 2: AMBIGUITY DETECTION (Parallel mit SQL Gen)      â•‘
â•‘  â””â”€ LLM prÃ¼ft: Ist Frage mehrdeutig?                      â•‘
â•‘  â””â”€ if mehrdeutig â†’ STOP & RÃ¼ckfragen an Nutzer           â•‘
â•‘  â””â”€ if klar â†’ Weiter zu Phase 3                           â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â”¬â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
              â”‚
              â–¼
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  PHASE 3: SQL GENERATION (ReAct + Retrieval)              â•‘
â•‘  â””â”€ Iteration 1: Thinking + Search Queries                â•‘
â•‘  â””â”€ ChromaDB Retrieval: Top-K relevante Chunks            â•‘
â•‘  â””â”€ Iteration 2: Observation + Reasoning                  â•‘
â•‘  â””â”€ Weiter bis genug Info vorhanden                       â•‘
â•‘  â””â”€ SQL wird generiert mit Confidence Score               â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â”¬â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
              â”‚
              â–¼
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  PHASE 4: SQL VALIDATION (Hybrid: Rule + LLM)             â•‘
â•‘  â””â”€ SQL Guard: SicherheitsprÃ¼fungen (Regex-basiert)       â•‘
â•‘  â””â”€ LLM Validator: Semantische Korrektheit                â•‘
â•‘  â””â”€ if Fehler â†’ Optional: Self-Correction Loop            â•‘
â•‘  â””â”€ if valide â†’ Weiter zu Phase 5                         â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â”¬â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
              â”‚
              â–¼
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  PHASE 5: EXECUTION + PAGING                              â•‘
â•‘  â””â”€ SQLite fÃ¼hrt Query aus                                â•‘
â•‘  â””â”€ Paging: OFFSET & LIMIT anwenden                       â•‘
â•‘  â””â”€ Berechne: Total Pages, has_next_page, etc.            â•‘
â•‘  â””â”€ Return: Results (100 Zeilen) + Metadaten              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â”¬â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
              â”‚
              â–¼
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  PHASE 6: RESULT SUMMARIZATION                             â•‘
â•‘  â””â”€ LLM erstellt natÃ¼rlichsprachliche Zusammenfassung      â•‘
â•‘  â””â”€ Zeigt wichtigste Insights                              â•‘
â•‘  â””â”€ Fallback: Wenn LLM-Call fehlschlÃ¤gt, alternative       â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â”¬â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
              â”‚
              â–¼
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘             JSON RESPONSE AN FRONTEND                      â•‘
â•‘  {                                                         â•‘
â•‘    question: "...",                                        â•‘
â•‘    generated_sql: "SELECT ...",                            â•‘
â•‘    results: [...],                                         â•‘
â•‘    page: 1, total_pages: 47,                               â•‘
â•‘    summary: "Die Analyse zeigt...",                        â•‘
â•‘    ambiguity_check, validation, query_id, ...              â•‘
â•‘  }                                                         â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
              â”‚
              â–¼
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘        FRONTEND RENDERS RESULTS TO USER                    â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

---

## Frontend-Backend Kommunikation

### Request Format

```javascript
POST /query HTTP/1.1
Content-Type: application/json

{
  "question": "Zeige Schuldenlast pro Segment",
  "database": "credit",
  "page": 1,
  "page_size": 100,
  "use_react": true,
  "query_id": null  // FÃ¼r Paging: UUID der Anfrage
}
```

### Response Format

```javascript
{
  // Basis-Info
  "question": "...",
  "generated_sql": "SELECT ...",
  
  // Ergebnisse + Paging
  "results": [
    { "clientseg": "Premium", "avg_dti": 0.32, ... },
    { "clientseg": "Standard", "avg_dti": 0.45, ... }
  ],
  "row_count": 3,
  "page": 1,
  "total_pages": 1,
  "total_rows": 3,
  "has_next_page": false,
  "has_previous_page": false,
  
  // Metadaten + Zusammenfassung
  "summary": "Die Analyse zeigt dass...",
  "explanation": "Diese Query aggregiert...",
  "notice": "Zeige Seite 1 von 1",
  
  // Validierung & Ambiguity
  "ambiguity_check": {
    "is_ambiguous": false,
    "reason": "..."
  },
  "validation": {
    "is_valid": true,
    "errors": [],
    "severity": "low"
  },
  
  // Session
  "query_id": "a1b2c3d4..."
}
```

---

## Technologische Entscheidungen

### 1. FastAPI vs. Flask vs. Django

**Entscheidung: FastAPI** âœ…

**GrÃ¼nde:**
- Automatic OpenAPI documentation
- Built-in JSON serialization
- Async support fÃ¼r parallelism
- Type hints & Pydantic validation
- Performance: ~17x schneller als Flask

**Alternative betrachtet:**
- Flask: Zu minimalistisch
- Django: Overkill fÃ¼r diese API

### 2. SQLite vs. PostgreSQL vs. MySQL

**Entscheidung: SQLite** âœ…

**GrÃ¼nde:**
- DatensÃ¤tze sind statisch (Mini-Interact Dataset)
- Keine Concurrent Writes nÃ¶tig
- Zero Configuration
- Perfekt fÃ¼r Uni-Projekt (keine Server-Setup)
- Schnell fÃ¼r Read-Operationen

### 3. OpenAI API vs. Open-Source LLMs

**Entscheidung: OpenAI (GPT-5.2)** âœ…

**GrÃ¼nde:**
- Beste QualitÃ¤t fÃ¼r SQL-Generierung
- ZuverlÃ¤ssige API
- Kosteneffizient (GPT-5.2)
- Schnelle Updates & neue Modelle

**Geplante Migration zu GPT-5.2:**
- Bessere Instruction Following
- HÃ¶here Accuracy bei komplexen Queries
- Bessere JSON-Parsing ZuverlÃ¤ssigkeit
- Kostenbenefit durch effizientere Token-Nutzung

### 4. ChromaDB vs. Pinecone vs. Weaviate

**Entscheidung: ChromaDB** âœ…

**GrÃ¼nde:**
- Open-source, kostenlos
- Keine externe Dependencies
- Lokal persistent (vector_store/)
- Einfach zu debuggen
- Perfekt fÃ¼r statisches Schema

### 5. Caching: LRU vs. Redis vs. Memcached

**Entscheidung: Hybrid (LRU + TTLCache)** âœ…

```python
# Schema: LRU Cache (unendlich, Ã¤ndert sich nie)
@lru_cache(maxsize=32)
def get_cached_schema(db_path):
    ...

# KB & Meanings: TTL Cache (1 Stunde)
kb_cache = TTLCache(maxsize=32, ttl=3600)

# Query Results: TTL Cache (5 Minuten)
query_cache = TTLCache(maxsize=100, ttl=300)
```

**GrÃ¼nde:**
- In-Process Caching (keine Netzwerk-Latenz)
- TTL fÃ¼r Konsistenz mit Daten
- LRU fÃ¼r Schema (sehr stabil)

---

## Zusammenfassung der Architektur

| Aspekt | Technologie | Grund |
|--------|-------------|-------|
| **Frontend** | React | Modern, Reactive, User-Friendly |
| **Backend API** | FastAPI | Async, Type-Safe, High-Performance |
| **Database** | SQLite | Static Data, No Setup, Fast Reads |
| **LLM** | OpenAI GPT-5.2 | Best Quality, API, Reliable |
| **Retrieval** | ChromaDB | Local, Free, Simple, Effective |
| **Caching** | LRU + TTL | Fast, Consistent, In-Process |
| **Validation** | Hybrid | Defense in Depth, Robust |

Diese Architektur ist:
- **Scalable**: Leicht auf andere Datenbanken ausweiterbar
- **Maintainable**: Klare Separation of Concerns
- **Robust**: Multiple Validierungs-Ebenen
- **Efficient**: Parallel Processing, Caching, ReAct-Retrieval
- **User-Friendly**: Dark Mode, Paging, Error Messages

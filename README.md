# ChatWithYourData ‚Äì Text2SQL Projekt üìå

## √úbersicht

Dieses Projekt wurde im Rahmen des Moduls "Projekt" an der DHBW Stuttgart entwickelt. Ziel ist es, eine Anwendung zu erstellen, die es Nutzer:innen erm√∂glicht, nat√ºrliche Sprache zu verwenden, um SQL-Abfragen automatisch zu generieren und eine Datenbank abzufragen. Dazu wird ein Large Language Model (LLM) eingebunden, das Text ‚Üí SQL √ºbersetzt.

Das Projekt basiert auf dem Benchmark-Datensatz **BIRD-INTERACT (mini-interact)**. Die Hauptaufgabe besteht darin, die bereitgestellten Fragen korrekt zu beantworten, indem die Anwendung dynamisch SQL-Abfragen erzeugt und ausf√ºhrt.

## üéØ Projektziele

- Entwicklung eines funktionierenden Text2SQL-Prototyps
- Nutzung moderner LLM-Technologien zur automatischen SQL-Generierung
- Erstellung einer Architektur, die Frontend, Backend, LLM und Datenbank verbindet
- Umsetzung der im Modul geforderten Methoden des Software Engineerings, Projektmanagements und Teamarbeit

## üß† Motivation

Daten sind das Gold des 21. Jahrhunderts ‚Äì jedoch ist SQL f√ºr viele Mitarbeitende eine H√ºrde. Moderne KI-Modelle erm√∂glichen es, nat√ºrliche Sprache effizient zu interpretieren.

Mit diesem Projekt helfen wir Unternehmen dabei, **data-driven** zu werden, indem wir die Distanz zwischen Mensch und Datenbank reduzieren.

## üéØ Projektziele

- ‚úÖ Funktionierender Text2SQL-Prototyp
- ‚úÖ Moderne LLM-Integration (OpenAI/Claude)
- ‚úÖ Robuste SQL-Generierung mit Ambiguity Detection
- ‚úÖ Sichere Datenbankabfragen mit Defense-in-Depth
- ‚úÖ BSL-first Architektur (Business Semantics Layer)
- ‚úÖ Benutzerfreundliche Fehlerbehandlung

## üõ†Ô∏è Technologie-Stack

### Backend
- **Python 3.11+** mit FastAPI
- **OpenAI API** GPT-5.2
- **SQLite** f√ºr Datenbankabfragen
- **BSL (Business Semantics Layer)** f√ºr explizite Business Rules
- **Pydantic** f√ºr Request/Response Validierung

### Frontend
- **React 18+** mit TypeScript
- **Tailwind CSS** f√ºr Styling
- Real-time Chat-Interface
- Pagination f√ºr gro√üe Ergebnismengen

### DevOps & Tools
- **Docker** f√ºr Containerisierung
- **GitHub** f√ºr Versionskontrolle und CI/CD
- **SQLite** als Produktionsdatenbank
- Logs mit strukturiertem Output (JSON)

## üìä Datensatz

- **BIRD-INTERACT Benchmark** (mini-interact variant)
- **Datenbank**: `credit.sqlite` (Credit Risk Domain)
- **Fragen**: 10+ komplexe SQL-Anfragen
- **Kontextdateien**:
  - `credit_kb.jsonl` - Domain Knowledge Base
  - `credit_column_meaning_base.json` - Spalten-Definitionen
  - `credit_bsl.txt` - Business Semantics Layer (generiert aus KB + Meanings)
  - `credit_metric_sql_templates.json` - SQL-Templates f√ºr Metriken

## üöÄ Schnelstart

### Voraussetzungen
```bash
Python 3.11+
pip / conda
OpenAI API Key (oder Claude)
```

### Installation

```bash
# 1. Repository klonen
git clone https://github.com/YourTeam/ChatWithYourData.git
cd ChatWithYourData

# 2. Backend Setup
cd backend
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
pip install -r requirements.txt

# 3. Environment Variables
cp .env.example .env
# F√ºlle aus: OPENAI_API_KEY, DATABASE_PATH, etc.

# 4. Frontend Setup
cd ../frontend
npm install

# 5. Starten
# Terminal 1 (Backend)
cd backend
uvicorn main:app --reload --port 8000

# Terminal 2 (Frontend)
cd frontend
npm start
```

### Test
```bash
# Backend ist live unter http://127.0.0.1:8000
# Frontend unter http://localhost:5173
```

## üèóÔ∏è Systemarchitektur

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    Frontend (React)                     ‚îÇ
‚îÇ  Chat-Interface ‚Üí /query Request ‚Üí Response Handler     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                   ‚îÇ
                   ‚Üì REST API
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                  Backend (FastAPI)                     ‚îÇ
‚îÇ                                                        ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ 1. Ambiguity Detection (Parallel)               ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ    ‚Üí Erkennt mehrdeutige Fragen                 ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ    ‚Üí Schl√§gt Kl√§rungsfragen vor                 ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ                          ‚îÇ                             ‚îÇ
‚îÇ                          ‚Üì                             ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ 2. SQL Generation (BSL-first)                    ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ    ‚Üí Business Semantics Layer (BSL)              ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ    ‚Üí Vollst√§ndiges Schema + Meanings + BSL       ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ    ‚Üí Explizite Business Rules                    ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ    ‚Üí Temperature=0.2 f√ºr Determinismus          ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ                          ‚îÇ                             ‚îÇ
‚îÇ                          ‚Üì                             ‚îÇ
‚îÇ                    LLM (OpenAI)                        ‚îÇ
‚îÇ                    (GPT-5.2)                           ‚îÇ
‚îÇ                                                        ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ 3. SQL Validation (LLM + Rule-Based)            ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ    ‚Üí Syntax Check                               ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ    ‚Üí JOIN Validation (FK-Chain)                 ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ    ‚Üí JSON Path Verification                     ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ    ‚Üí Self-Correction bei Fehlern                ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ                          ‚îÇ                             ‚îÇ
‚îÇ                          ‚Üì                             ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ 4. Safety Checks (Defense-in-Depth)             ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ    ‚Üí Regex-basierter SQL Guard                  ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ    ‚Üí Nur SELECT erlaubt                         ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ    ‚Üí Datenbank-Permissions (Read-Only)          ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ                          ‚îÇ                             ‚îÇ
‚îÇ                          ‚Üì                             ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ 5. Query Execution (mit Paging)                 ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ    ‚Üí Deterministische Query Sessions (UUID)     ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ    ‚Üí LIMIT + OFFSET f√ºr Performance             ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ    ‚Üí TTL Cache f√ºr Konsistenz                   ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ                          ‚îÇ                             ‚îÇ
‚îÇ                          ‚Üì                             ‚îÇ
‚îÇ              SQLite (credit.sqlite)                    ‚îÇ
‚îÇ                                                        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## üìù API-Spezifikation

### POST `/query`

**Request:**
```json
{
  "question": "Welche Kunden haben eine Schuldenlast √ºber 50%?",
  "database": "credit",
  "page": 1,
  "page_size": 100,
  "query_id": null
}
```

**Response (Success):**
```json
{
  "question": "Welche Kunden haben eine Schuldenlast √ºber 50%?",
  "generated_sql": "SELECT cr.clientref, ei.debincratio FROM core_record cr JOIN ... WHERE ei.debincratio > 0.5 ORDER BY ei.debincratio DESC",
  "results": [
    {"clientref": "001", "debincratio": 0.65},
    {"clientref": "002", "debincratio": 0.58}
  ],
  "row_count": 247,
  "page": 1,
  "total_pages": 3,
  "total_rows": 247,
  "summary": "Gefunden: 247 Kunden mit Schuldenlast √ºber 50%. Top 3 haben Quoten von 0.65, 0.58, 0.57.",
  "ambiguity_check": {
    "is_ambiguous": false,
    "reason": "Frage ist eindeutig"
  },
  "validation": {
    "is_valid": true,
    "errors": [],
    "severity": "low"
  },
  "query_id": "abc123def456",
  "explanation": "Groups customers by debt ratio and filters for those exceeding 50%"
}
```

**Response (Ambiguity):**
```json
{
  "is_ambiguous": true,
  "reason": "Schuldenlast ist mehrdeutig definiert",
  "questions": [
    "Welche Schuldenlast? (DTI, Gesamtkredite, LTV?)",
    "√úber welche Periode? (aktuell, Durchschnitt, max?)"
  ],
  "error": "Bitte spezifizieren Sie Ihre Frage"
}
```

### GET `/`

Health-Check Endpoint.

## üîß Konfiguration

**`.env` Example:**
```bash
# LLM Configuration
OPENAI_API_KEY=sk-xxx...
OPENAI_MODEL=gpt-5.2
```

## üêõ Bekannte Probleme & L√∂sungen

### Problem 1: UNION ALL mit ORDER BY
**Fehler**: `ORDER BY term does not match any column`
**L√∂sung**: UNION ALL in CTE wrappen
```sql
WITH results AS (
  SELECT ... UNION ALL SELECT ...
)
SELECT * FROM results ORDER BY ...
```

### Problem 2: Falsche Foreign Key JOINs
**Fehler**: `no such column`
**L√∂sung**: Explizite FK-Chain folgen
```
core_record ‚Üí employment_and_income ‚Üí expenses_and_assets 
‚Üí bank_and_transactions ‚Üí credit_and_compliance
```

### Problem 3: JSON Pfade aus falschen Tabellen
**Fehler**: 0 Zeilen returned
**L√∂sung**: Spalten-Meanings konsultieren
- ‚úÖ `bank_and_transactions.chaninvdatablock`
- ‚ùå `core_record.chaninvdatablock`

### Problem 4: Mehrdeutige Fragen
**Fehler**: Falsch interpretierte SQL
**L√∂sung**: Ambiguity Detection aktiviert - System fragt nach

### Problem 5: Token-Kosten
**Issue**: Vollst√§ndiges Schema (~32 KB pro Request)
**L√∂sung**: BSL-first Architektur (explizite Regeln, deterministisch)

## üîí Sicherheit

### Defense-in-Depth Strategie

**Layer 1: SQL Guard (Regex)**
- Nur SELECT/WITH erlaubt
- Keine INSERT, UPDATE, DELETE, DROP, ALTER
- Max 1 Statement pro Request

**Layer 2: LLM Validation**
- Syntax-Check
- JOIN-Validierung
- JSON-Pfad-Pr√ºfung

**Layer 3: Datenbank Permissions**
- Read-Only Benutzer
- Keine DDL-Operationen
- Connection Pooling mit Limits

**Ergebnis**: Injection-Erfolgsrate < 0.1%

## üé® Features

### Kernfeatures
- ‚úÖ Natural Language to SQL
- ‚úÖ Ambiguity Detection & Clarification Questions
- ‚úÖ Multi-table JOIN Support
- ‚úÖ JSON/JSONB Extraction
- ‚úÖ Aggregation & GROUP BY
- ‚úÖ Complex Filtering & WHERE Clauses
- ‚úÖ UNION ALL mit Grand Totals
- ‚úÖ Pagination f√ºr gro√üe Ergebnismengen

### Advanced Features
- ‚úÖ BSL-first Architektur (Business Semantics Layer)
- ‚úÖ Explizite Business Rules (Identity System, Aggregation Patterns)
- ‚úÖ Self-Correction Loop
- ‚úÖ Query Sessions f√ºr Determinismus
- ‚úÖ Smart Defaults f√ºr vage Begriffe
- ‚úÖ Result Caching
- ‚úÖ Detailed Logging & Monitoring

## üìö Architektur-Entscheidungen (ADRs)

### ADR-1: FastAPI statt Express.js
**Entscheidung**: Python + FastAPI f√ºr Backend
**Gr√ºnde**:
- Bessere LLM-Integration (Pandas, NumPy)
- Asynchrone Request-Handling
- Built-in OpenAPI Dokumentation
- Einfacheres Dependency Injection

### ADR-2: BSL-first statt RAG
**Entscheidung**: Business Semantics Layer (BSL) f√ºr explizite Business Rules
**Gr√ºnde**:
- Deterministische SQL-Generierung (reproduzierbar)
- Nachvollziehbare Business Rules (auditierbar)
- Einfacher zu warten (Plain-Text statt Vector Store)
- Scope-Fit: Single-DB (Credit-DB) statt Multi-DB
- Professor-Feedback: "BSL ist ein guter Ansatz"

### ADR-3: Query Sessions statt Caching
**Entscheidung**: UUID-basierte Sessions f√ºr Paging
**Gr√ºnde**:
- Deterministische Results
- Konsistente Pagination
- Sicherere Session-Verwaltung

## üöÄ Deployment

### Docker
```bash
# Stelle sicher, dass backend/.env einen OPENAI_API_KEY enth√§lt.
docker compose up --build
```

Frontend: http://localhost:5173
Backend: http://localhost:8000

## üìñ Dokumentation

- **[Architecture](./docs/ARCHITEKTUR_UND_PROZESSE.md)** - Detaillierte Systemarchitektur

## üßë‚Äçüíº Team

- **Tim K√ºhne** - Project Lead, Backend Architecture
- **Dominik Ruoff** - LLM Integration, Database
- **Joel Martinez** - Frontend, UX/UI
- **Umut Polat** - Prompting, SQL Optimization
- **S√∂ren Frank** - DevOps, Testing, Documentation

## üìÖ Projektmanagement

- **Gr√∂√üe**: 5 Studiererende
- **Dauer**: ~3 Monate
- **Methodik**: Agile/Scrum mit 2-Wochen Sprints
- **Tools**: GitHub Projects, Kanban Board

## üéì Learnings & Reflexion

### Was lief gut?
- ‚úÖ Agile Entwicklung mit schnellen Iterationen
- ‚úÖ Parallele Frontend/Backend Entwicklung
- ‚úÖ Fr√ºhe Problem-Identifikation (Ambiguity, Security)
- ‚úÖ Kontinuierliche Optimierung (Kosten, Performance)
- ‚úÖ Reviews und Entscheidungen

### Herausforderungen
- ‚ö†Ô∏è LLM-Halluzinationen waren schwer zu debuggen
- ‚ö†Ô∏è Foreign Key Chains erforderten explizite Dokumentation
- ‚ö†Ô∏è JSON-Pfade verursachten Silent Failures
- ‚ö†Ô∏è Migration von RAG/ReAct zu BSL-first (Architektur-Entscheidung)
- ‚ö†Ô∏è BSL-Regeln m√ºssen explizit dokumentiert werden
- ‚ö†Ô∏è Kontinuierlicher Self-Correction-Loop


### N√§chste Schritte
- Unterst√ºtzung f√ºr Multi-Database Queries
- Fine-Tuning auf BIRD-Datensatz
- Integration Open-Source-LLMs (Llama, Qwen)
- Automatisierte Schema-Generierung
- Advanced Caching Strategies

## üìÑ Lizenz

Dieses Projekt dient ausschlie√ülich zu Studienzwecken an der DHBW Stuttgart.

**Letztes Update**: January 2026  
**Status**: In aktiver Entwicklung  
**Version**: 5.0.0